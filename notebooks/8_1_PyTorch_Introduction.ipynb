{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: PyTorch & TorchText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Author: Konstantin Todorov_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome. This laboratory is meant to teach you about the basics of PyTorch - one of the most widely used python libraries for machine learning out there. In addition to it, you will learn about TorchText - one of the integrated libraries that is meant to help when training Natural Language Processing (NLP) models. In addition to that, TorchText also provides readily available datasets such as the IMDB one that we will make use of in this setup.\n",
    "\n",
    "At the end of this lab, you will know how to train your own basic model, as well as evaluate and make use of techniques to improve your performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes on implementation:\n",
    "\n",
    "* You should write your code and answers in this IPython Notebook: http://ipython.org/notebook.html. If you have problems, please contact your teaching assistant.\n",
    "* Please write your answers right below the questions.\n",
    "* Among the first lines of your notebook should be \"%pylab inline\". This imports all required modules, and your plots will appear inline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [20,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell makes sure that you have all the necessary libraries installed\n",
    "\n",
    "import sys\n",
    "import platform\n",
    "from importlib.util import find_spec, module_from_spec\n",
    "\n",
    "def check_newer_version(version_inst, version_nec):\n",
    "    version_inst_split = version_inst.split('.')\n",
    "    version_nec_split = version_nec.split('.')\n",
    "    for i in range(min(len(version_inst_split), len(version_nec_split))):\n",
    "        if int(version_nec_split[i]) > int(version_inst_split[i]):\n",
    "            return False\n",
    "        elif int(version_nec_split[i]) < int(version_inst_split[i]):\n",
    "            return True\n",
    "    return True\n",
    "\n",
    "\n",
    "module_list = [('torch', '1.8.0'),\n",
    "               ('torchtext', '0.9.0'), \n",
    "               ('matplotlib', '3.0.0'), \n",
    "               ('numpy', '1.13.1'), \n",
    "               ('python', '3.6.2')]\n",
    "\n",
    "packages_correct = True\n",
    "packages_errors = []\n",
    "\n",
    "for module_name, version in module_list:\n",
    "#     if module_name == 'scikit-learn':\n",
    "#         module_name = 'sklearn'\n",
    "    if 'python' in module_name:\n",
    "        python_version = platform.python_version()\n",
    "        if not check_newer_version(python_version, version):\n",
    "            packages_correct = False\n",
    "            error = f'Update {module_name} to version {version}. Current version is {python_version}.'\n",
    "            packages_errors.append(error) \n",
    "            print(error)\n",
    "    else:\n",
    "        spec = find_spec(module_name)\n",
    "        if spec is None:\n",
    "            packages_correct = False\n",
    "            error = f'Install {module_name} with version {version} or newer, it is required for this assignment!'\n",
    "            packages_errors.append(error) \n",
    "            print(error)\n",
    "        else:\n",
    "            x = __import__(module_name)\n",
    "            if hasattr(x, '__version__') and not check_newer_version(x.__version__, version):\n",
    "                packages_correct = False\n",
    "                error = f'Update {module_name} to version {version}. Current version is {x.__version__}.'\n",
    "                packages_errors.append(error) \n",
    "                print(error)\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    packages_correct = False\n",
    "    error = \"\"\"Please, don't use google colab!\n",
    "It will make it much more complicated for us to check your homework as it merges all the cells into one.\"\"\"\n",
    "    packages_errors.append(error) \n",
    "    print(error)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "packages_errors = '\\n'.join(packages_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We must import all required libraries. These should be enough. \n",
    "# In case you need extra libraries, feel free to import them in cells below.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We make use of a GPU if one is available on the current system. \n",
    "# Using GPU can make the training process and matrix operations magnitudes faster\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set a seed manually for reproducing purposes. \n",
    "# This will ensure that every time you run the notebook on the same machine you will receive the same results\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "if device == 'cuda':\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Preparing the data\n",
    "\n",
    "We will use TorchText and more specifically the IMDB sentiment analysis dataset. We first load it from the `torchtext.datasets` namespace. For the purpose of testingwe can load only the `train` split. Note that different sets have different splits. You can see all available datasets and their properties [here](https://pytorch.org/text/stable/datasets.html#imdb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imdb_iterator = torchtext.datasets.IMDB(split='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's see what kind of data we are working with. The `train_imdb_iterator` is a python iterator object and as such, we can iterate through it by calling the `next` function for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label, text = next(train_imdb_iterator)\n",
    "\n",
    "print(f'Text sequence:\\n{text}')\n",
    "print(f'Sentiment: {label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label, text = next(train_imdb_iterator)\n",
    "\n",
    "print(f'Text sequence:\\n{text}')\n",
    "print(f'Sentiment: {label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, each element from the dataset contains an IMDB review and a sentiment ground truth label. The label can be either positive (pos) or negative (neg). Our goal is to train a machine learning model which can predict the sentiment of a given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext.datasets\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import Vocab\n",
    "from collections import Counter\n",
    "\n",
    "def get_tokenized_data(tokenizer):\n",
    "    train_iterator = torchtext.datasets.IMDB(split='train')\n",
    "    \n",
    "    counter = Counter()\n",
    "    for (label, line) in train_iterator:\n",
    "        counter.update(tokenizer(line))\n",
    "        \n",
    "    return counter\n",
    "\n",
    "def build_vocabulary(data_counter, vectors=None):\n",
    "    vocab = Vocab(data_counter, min_freq=1, vectors=vectors)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')\n",
    "data_counter = get_tokenized_data(tokenizer)\n",
    "vocab = build_vocabulary(data_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text, vocab, tokenizer):\n",
    "    return [vocab[token] for token in tokenizer(text)]\n",
    "\n",
    "def tokenize_label(label):\n",
    "    if label == 'neg':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_text('here is the an example', vocab, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_label('pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate_batch(batch, vocab, tokenizer):\n",
    "    batch_size = len(batch)\n",
    "    label_list, text_list = [], []\n",
    "    \n",
    "    # Tokenize labels and texts\n",
    "    for (label, text) in batch:\n",
    "        label_list.append(tokenize_label(label))\n",
    "        tokenized_text = tokenize_text(text, vocab, tokenizer)\n",
    "        text_list.append(tokenized_text)\n",
    "\n",
    "    # Put all texts into a single numpy array of uniform length\n",
    "    # For all sequences that are shorther than the maximum length, pad to the right with 0\n",
    "    lengths = [len(text) for text in text_list]\n",
    "    max_length = max(lengths)\n",
    "    padded_sequences = np.zeros((batch_size, max_length), dtype=np.int64)\n",
    "    for i, (length, text) in enumerate(zip(lengths, text_list)):\n",
    "        padded_sequences[i][0:length] = text_list[i][0:length]\n",
    "        \n",
    "    # Finally transform the arrays into tensors and return to the dataloader\n",
    "    label_tensor = torch.tensor(label_list, dtype=torch.float32).to(device)\n",
    "    sequences_tensor = torch.from_numpy(padded_sequences).to(device)\n",
    "    return sequences_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how many unique tokens we have in our vocabularies\n",
    "\n",
    "print(f\"Unique tokens in vocabulary: {len(vocab):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also check the most common tokens in our vocabulary\n",
    "\n",
    "print(vocab.freqs.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocabularies contain so called **i**ndex **to s**tring vector which is usually represented as a list of string where the index of an element represents the index of this token in the vocabulary. We can access this list in a TorchText data field using the `.itos` property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vocab.itos[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, vocabularies also contain the opposite mapping, namely **s**tring **to i**ndex which is a dictionary with the keys being the tokens and the values - the corresponding vocabulary indices. This can be examined using the `.stoi` property of a TorchText data field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(vocab.stoi.items())[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final data preparation, we must take care of the way we _access_ the data. To this end, in Python we use iterators. Specifically, in TorchText, we can make use of the `BucketIterator` object which presents us with numerous advantages over traditional iterators. It works directly with TorchText datasets, it allows us to pass a `device` argument which automatically moves the data that is iterated over to the corresponding device. We can also sort within a batch (which sometimes is required for training) and most importantly, it can be configured so that the data is iterated over _batches_. This is an arrangement of the data organized in sets or groups. This allows us to work with multiple elements in one iteration and speeds up the training and evaluation processes tremendously.\n",
    "\n",
    "Please populate the `get_iterators` function. Use the `BucketIterator` and make sure to also set `batch_size`, `device` and `sort_within_batch` arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "def get_dataloaders(batch_size, vocab, tokenizer):\n",
    "    train_iter, test_iter = torchtext.datasets.IMDB()\n",
    "    train_dataset, test_dataset = list(train_iter), list(test_iter)\n",
    "    num_train = int(len(train_dataset) * 0.95)\n",
    "    split_train_, split_valid_ = random_split(\n",
    "        train_dataset,\n",
    "        [num_train, len(train_dataset) - num_train])\n",
    "    \n",
    "    train_dataloader = DataLoader(\n",
    "        split_train_,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=lambda x: collate_batch(x, vocab, tokenizer))\n",
    "    \n",
    "    valid_dataloader = DataLoader(\n",
    "        split_valid_,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=lambda x: collate_batch(x, vocab, tokenizer))\n",
    "    \n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=lambda x: collate_batch(x, vocab, tokenizer))\n",
    "\n",
    "    return train_dataloader, valid_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "train_dataloader, valid_dataloader, test_dataloader = get_dataloaders(BATCH_SIZE, vocab, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Module vs nn.functional\n",
    "\n",
    "The `torch.nn.Module` or simply `nn.Module` is arguably one of the most important parts and what many refer to as the \"cornerstone\" of PyTorch. In order to build a machine learning model that is able to backpropagate automatically, one must define an `nn.Module` object and then invoke its `forward` method to run it. This is the Object Oriented way of doing things. On the other hand, people also make use of `nn.functional` which provides some layers/activations in the form of functions that can be directly called on the input rather than defining the an object. For example, in order to rescale an image tensor, you call `nn.functional.interpolate` on an image tensor.\n",
    "\n",
    "### Understanding Stateful-ness\n",
    "\n",
    "Normally, any layer can be seen as a function. For example, a convolutional operation is just a bunch of multiplication and addition operations. So, it makes sense for us to just implement it as a function right? But wait, the layer holds weights which need to be stored and updated while we are training. Therefore, from a programmatic angle, a layer is more than function. It also needs to hold data, which changes as we train our network.\n",
    "\n",
    "It must be understood that the data held by the convolutional layer **changes**. This means that the layer has a state which changes as we train. For us to implement a function that does any operation, we would also need to define a data structure to hold the weights of the layer separately from the function itself. And then, make this external data structure an input to our function. Or just to beat the hassle, we could just define a class to hold the data structure, and make convolutional operation as an member function. This would really ease up our job, as we don't have to worry about stateful variables existing outside of the function. \n",
    "\n",
    "This all seems rather complicated, but thankfully, PyTorch comes to the rescue by exposing the `nn.Module` objects where we have weights or other pre-defined states which define the behaviour of the layers. In the cases where no state or weights are required, one could use the nn.functional - examples being resizing (`nn.functional.interpolate`) or average pooling (`nn.functional.AvgPool2d`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Parameter\n",
    "\n",
    "Before we step towards writing our own model, we must look into one other important part of PyTorch, namely the `nn.Parameter` class. \n",
    "\n",
    "Each `nn.Module` has a `parameters()` function which returns, well, it's trainable parameters. We have to implicitly define what these parameters are. However, when we use internal `nn.Module` objects, all of the module training weights are implemented as `nn.Parameter`. If you try to assign a tensor to the `nn.Module` object, it won't show up in the `parameters()` unless you define it as `nn.Parameter` object. This has been done to facilitate scenarios where you might need to cache a non-differentiable tensor.\n",
    "\n",
    "Let's consider the following example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class net1(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv = nn.Linear(10,5)\n",
    "    self.tens = torch.ones(3,4)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    return self.linear(x)\n",
    "\n",
    "##########################################################\n",
    "\n",
    "class net2(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv = nn.Linear(10,5) \n",
    "    self.tens = nn.Parameter(torch.ones(3,4))\n",
    "    \n",
    "  def forward(self, x):\n",
    "    return self.linear(x)\n",
    "\n",
    "##########################################################\n",
    "\n",
    "class net3(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv = nn.Linear(10,5)\n",
    "    self.net  = net2()\n",
    "    \n",
    "  def forward(self, x):\n",
    "    return self.linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having defined those simple networks, let's invoke the `named_parameters` function of each. This calls the `parameters` function and also returns the name of each parameter. Notice how the parameters differ across the three networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_named_parameters(model):\n",
    "    for name, parameter in model.named_parameters():\n",
    "        print(f' ** {name}: {parameter}')\n",
    "    \n",
    "print('# Net 1:')\n",
    "print_named_parameters(net1())\n",
    "\n",
    "print('\\n# Net 2:')\n",
    "print_named_parameters(net2())\n",
    "\n",
    "print('\\n# Net 3:')\n",
    "print_named_parameters(net3())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining your own model\n",
    "\n",
    "Now it's time to define our own PyTorch model which we will train on sentiment analysis detection over the IMDB dataset. \n",
    "\n",
    "We will use the model defined in this example\n",
    "![Sentiment analysis model](https://pytorch.org/tutorials/_images/text_sentiment_ngrams_model.png \"Sentiment analysis model\") \n",
    "\\[[reference](https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html#define-the-model)\\]\n",
    "\n",
    "For simplicity reasons, we will not use an embedding bag but rather a simple embedding layer. This is the first inner module we define It uses `input_dimension` and `embedding_dimension` arguments that can differ based on our use case or experiment. After, a fully connected linear layer which must map down the `embedding_dimension` to an `output_dimension` which in our case would be 1 as we have two labels which can be either 0 or 1.\n",
    "\n",
    "We also add uniform weights initialization. This can often improve and/or speed up the training process. We also add optional embeddings weights initialization from external source (more on this later).\n",
    "\n",
    "Finally, the forward iteration must be implemented. First, a pass through the embedding layer must be performed before taking the average value of the embeddings. Finally, the output must be mapped down using the fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalysisModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dimension,\n",
    "        embedding_dimension,\n",
    "        output_dimension,\n",
    "        pretr_embeddings=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self._embedding_layer = nn.Embedding(input_dimension, embedding_dimension)    \n",
    "        self._fully_connected_layer = nn.Linear(embedding_dimension, output_dimension)\n",
    "        self._init_weights(pretr_embeddings)\n",
    "    \n",
    "    # Use uniform initialization of the weights\n",
    "    def _init_weights(self, pretr_embeddings):\n",
    "        initrange = 0.5\n",
    "        \n",
    "        # We add an option to initialize the embeddings from external source\n",
    "        if pretr_embeddings is not None:\n",
    "            self._embedding_layer.weight.data.copy_(pretr_embeddings)\n",
    "        else:\n",
    "            self._embedding_layer.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "        self._fully_connected_layer.weight.data.uniform_(-initrange, initrange)\n",
    "        self._fully_connected_layer.bias.data.zero_()\n",
    "\n",
    "    def forward(self, input_batch):\n",
    "        # Process the input batch and return a result that can be processed from the loss function\n",
    "        # input_batch is of shape - [ batch_size x max_length ]\n",
    "        \n",
    "        embeddings = self._embedding_layer.forward(input_batch)\n",
    "        # embeddings are of shape - [ batch_size x max_length x embedding_dimension ]\n",
    "        \n",
    "        embeddings_mean = embeddings.mean(dim=1)\n",
    "        # embeddings_mean is now - [ batch_size x embedding_dimension ]\n",
    "        \n",
    "        result = self._fully_connected_layer.forward(embeddings_mean)\n",
    "        # finally, our result is - [ batch_size x 1 ]\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "INPUT_DIMENSION = len(vocab)\n",
    "EMBEDDING_DIMENSION = 300\n",
    "OUTPUT_DIMENSION = 1\n",
    "\n",
    "# We can now initialize our model. Note the .to(device) part. \n",
    "# This transfers the model to the previously defined device (could be a GPU) for faster computation.\n",
    "\n",
    "model = SentimentAnalysisModel(\n",
    "    INPUT_DIMENSION, \n",
    "    EMBEDDING_DIMENSION, \n",
    "    OUTPUT_DIMENSION).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now check how our model looks like\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have the model, we must define a loss function. Here, we will make use of the [`BCEWithLogitsLoss`](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html) defined in PyTorch. This loss combines a Sigmoid layer and the BCELoss in one single class. This version is more numerically stable than using a plain Sigmoid followed by a BCELoss as, by combining the operations into one layer, we take advantage of the log-sum-exp trick for numerical stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next simple example shows how we use our loss function during training. \n",
    "\n",
    "Our model outputs prediction (logit) for each entry. Let's assume we have three elements in our dataset. As our task is a binary classification one, our model outputs a value which is then transformed into a probability (value between 0 and 1) using a sigmoid function. \n",
    "\n",
    "On the other side, our targets are usually integers. In the case of binary classification, they can be only 0 or 1. For the purpose of comparison with the probabilities which are floats, we use float type for the labels too. \n",
    "\n",
    "Finally, we pass the model output and the original targets to the loss function which computes a number - that is our loss. The lower and closer to 0 the loss value is, the better are our model predictions resembling the true labels. \n",
    "\n",
    "During training, we must also call the `.backward()` function of the loss result in order to back-propagate through the model and update our weights. \n",
    "\n",
    "_Note: Execute the next cell multiple times to see how the loss changes depending on the different targets and model outputs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = torch.randn(3)\n",
    "print(f'Model output: {model_output}')\n",
    "target = torch.empty(3).random_(2)\n",
    "print(f'Target: {target}')\n",
    "test_criterion = nn.BCEWithLogitsLoss()\n",
    "output = test_criterion.forward(model_output, target)\n",
    "print(f'Calculated loss: {output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, an `torch.optim` Optimizer must be defined. This is used to traverse through the parameter space and find the optimal weights for the model.\n",
    "\n",
    "Initialize the [`Adam`](https://pytorch.org/docs/stable/optim.html#torch.optim.Adam) optimizer. Stick to the default arguments. Later, you can experiment with different learning rates that can change the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we go to the training process, we must prepare a function that can calculate the accuracy of the model. Due to the nature of the training, our model is outputting raw predictions while we also have ground truth values. These are both in the forms of vectors, although the predictions could be float numbers while the true values are usually integers.\n",
    "\n",
    "Implement a function, which takes these two vectors and calculates a value between 0 and 1 which corresponds to the accuracy. Even more so, we are working with batches and therefore have vectors of such values, e.g. if we have predicted [0, 1, 0, 1] and the ground truth is [1, 1, 1, 1], then the function should output 0.5. Keep in mind that the `calculate_accuracy` function accepts and works with tensors and not regular lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(predictions, ground_truth):\n",
    "    # Returns accuracy per batch\n",
    "    \n",
    "    # transform the predictions into probabilities\n",
    "    predictions = torch.sigmoid(predictions)\n",
    "    \n",
    "    # round the predictions into integers\n",
    "    rounded_predictions = torch.round(predictions)\n",
    "    \n",
    "    # compare which of the predictions are equal to their corresponding true value\n",
    "    correct = (rounded_predictions == ground_truth).float()\n",
    "    \n",
    "    # take the average for all elements in one batch\n",
    "    accuracy = correct.sum() / len(correct)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: Training\n",
    "\n",
    "We can now proceed to the training of our defined model. \n",
    "\n",
    "First you will see the `zero_optimizer_gradients` function. This is necessary during training to avoid problems with gradients accumulating. We usually execute this before we backpropagate to avoid using gradients from previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_optimizer_gradients(optimizer):\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now proceed to the training process. We define one _epoch_ to be the period where we iterate over **all** elements (or batches) in our dataset. Usually, during training we can iterate over many epochs until we are comfortable with our results. Starting, with the smallest iteration, we a function which works on batch-level. The most important steps during one such pass are:\n",
    "* Perform a forward pass through the model\n",
    "* Perform a forward pass through the loss function using the predicted labels from the model\n",
    "* Calculate the accuracy by comparing the predictions and the ground truth\n",
    "\n",
    "This function can be used both during training (when we update the parameters of the network) and during evaluation (where we only want to predict labels). To distinguish the two modes, we use the `eval_mode` argument. When we are training (i.e. `eval_mode == False`) we must perform a backpropagation from the loss function and perform a step in the parameter space using the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_batch_iteration(\n",
    "    batch,\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    eval_mode):\n",
    "\n",
    "    if not eval_mode:\n",
    "        zero_optimizer_gradients(optimizer)\n",
    "    \n",
    "    text, label = batch\n",
    "    \n",
    "    predictions = model.forward(text).squeeze(1)\n",
    "    loss = criterion.forward(predictions, label)\n",
    "    accuracy = calculate_accuracy(predictions, label)\n",
    "\n",
    "    if not eval_mode:\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return loss.item(), accuracy.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having passed through one bach, we then define a function which takes care for a whole epoch iteration. In one epoch, we must process _all_ batches of our data and save the loss and accuracy values that we compute for each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_epoch_iteration(\n",
    "    model,\n",
    "    dataloader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    eval_mode):\n",
    "    \n",
    "    epoch_losses = []\n",
    "    epoch_accuracies = []\n",
    "    \n",
    "    if not eval_mode:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    for batch in dataloader:\n",
    "        loss, accuracy = perform_batch_iteration(batch, model, criterion, optimizer, eval_mode)\n",
    "        epoch_losses.append(loss)\n",
    "        epoch_accuracies.append(accuracy)\n",
    "\n",
    "    return np.mean(epoch_losses), np.mean(epoch_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, for the full training process, we perform multiple epoch iterations for both the training and the validation datasets. We keep the best validation score as a reference. In practice, one must keep reference to the model state and best validation results at the time but for simplicity reasons we skip this.\n",
    "\n",
    "_Note: As an optional exercise, you can try to define your own `train_model_v2` function where you do this._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, valid_dataloader, criterion, optimizer, epochs):\n",
    "    print('Starting training...')\n",
    "    \n",
    "    train_losses, train_accuracies = [], []\n",
    "    valid_losses, valid_accuracies = [], []\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # iterate over the train data\n",
    "        loss, accuracy = perform_epoch_iteration(\n",
    "            model,\n",
    "            train_dataloader,\n",
    "            criterion,\n",
    "            optimizer,\n",
    "            eval_mode=False)\n",
    "\n",
    "        # store the train loss and accuracy for later\n",
    "        train_losses.append(loss)\n",
    "        train_accuracies.append(accuracy)\n",
    "        \n",
    "        print(f'Epoch: {epoch:02}')\n",
    "        print(f'\\tTrain Loss: {loss:.3f} | Train Acc: {accuracy*100:.2f}%', end='')\n",
    "        \n",
    "        # iterate over the train data\n",
    "        valid_loss, valid_accuracy = perform_epoch_iteration(\n",
    "            model,\n",
    "            valid_dataloader,\n",
    "            criterion,\n",
    "            None,\n",
    "            eval_mode=True)\n",
    "\n",
    "        # store the train loss and accuracy for later\n",
    "        valid_losses.append(valid_loss)\n",
    "        valid_accuracies.append(valid_accuracy)\n",
    "        \n",
    "        print(f'| Valid Loss: {valid_loss:.3f} | Valid Acc: {valid_accuracy*100:.2f}%')\n",
    "            \n",
    "    # finally, return the stored lists\n",
    "    return train_losses, train_accuracies, valid_losses, valid_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "\n",
    "N_EPOCHS = 10\n",
    "\n",
    "train_losses, train_accuracies, valid_losses, valid_accuracies = train_model(\n",
    "    model,\n",
    "    train_dataloader,\n",
    "    valid_dataloader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    N_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compare the train and validation losses and how they changed during the different epochs\n",
    "\n",
    "plt.plot(train_losses, label='Train')\n",
    "plt.plot(valid_losses, label='Validation')\n",
    "plt.title('Loss during training')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can do the same thing with the accuracy\n",
    "\n",
    "plt.plot(train_accuracies, label='Train')\n",
    "plt.plot(valid_accuracies, label='Validation')\n",
    "plt.title('Accuracy during training')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that as training progresses, performance over the validation dataset stops improving as much. If we continue to train, we risk achieving so-called overfitting. This is what happens when our model learns the training data \"too much\" and starts forgetting about generic features that are required when dealing with unseen data (which is the case with the validation data). This is something that we must be careful about in practice as it can prevent us from applying our model on actual real world problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After we have fully trained our model,\n",
    "# we can let it run over the test data and check the results that we receive\n",
    "\n",
    "test_loss, test_acc = perform_epoch_iteration(model, test_dataloader, criterion, None, True)\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part IV: Pre-trained embeddings\n",
    "\n",
    "In recent years, pre-trained embeddings have emerged as a very powerful tool for quickly optimizing the training process. When you define an embedding layer simply as it is, its weights are initialized _randomly_. This means that in order to learn which words are contextually close to one another, we must train the model from scratch, often for long periods of time. To overcome this limitation, pre-trained embeddings come to life. If we simply replace the randomly initialized embeddings with ones that have already been trained in another model, than surely we can gain some benefits, at least time wise. \n",
    "\n",
    "There are many pre-trained vectors and embeddings ones out there. As a starting point, you are advised to use GloVe which come built in the TorchText library. They can be accessed using the `vectors` argument during building the vocabulary. The most commonly used GloVe vectors are `glove.6B.300d` meaning that they have been trained on 6 billion tokens and have dimensionality of 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's build a new vocabulary, this time using pre-trained vectors\n",
    "pretr_vocab = build_vocabulary(data_counter, vectors='glove.6B.300d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dataloaders, this time using the new vocabulary\n",
    "pretr_train_dataloader, pretr_valid_dataloader, pretr_test_dataloader = \\\n",
    "    get_dataloaders(BATCH_SIZE, pretr_vocab, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a new SentimentAnalysisModel, this time using pretrained embeddings\n",
    "pretr_model = SentimentAnalysisModel(\n",
    "    INPUT_DIMENSION,\n",
    "    EMBEDDING_DIMENSION, \n",
    "    OUTPUT_DIMENSION,\n",
    "    pretr_embeddings=pretr_vocab.vectors).to(device)\n",
    "\n",
    "pretr_optimizer = torch.optim.Adam(pretr_model.parameters())\n",
    "pretr_criterion = nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the new model with pre-trained embeddings\n",
    "(pretr_train_losses, pretr_train_accuracies, \n",
    " pretr_valid_losses, pretr_valid_accuracies) = train_model(\n",
    "    pretr_model,\n",
    "    pretr_train_dataloader,\n",
    "    pretr_valid_dataloader,\n",
    "    pretr_criterion,\n",
    "    pretr_optimizer,\n",
    "    N_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as before, we perform an epoch iteration over the test dataset \n",
    "pretr_test_loss, pretr_test_acc = perform_epoch_iteration(\n",
    "    pretr_model,\n",
    "    pretr_test_dataloader,\n",
    "    pretr_criterion,\n",
    "    None,\n",
    "    True)\n",
    "\n",
    "# Print the results. Are those better than the non-pretrained ones?\n",
    "print(f'Test Loss: {pretr_test_loss:.3f} | Test Acc: {pretr_test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compare the loss and accuracy values of the two models\n",
    "\n",
    "plt.plot(pretr_valid_losses, label='GloVe pre-trained')\n",
    "plt.plot(valid_losses, label='Randomly initialized')\n",
    "plt.legend()\n",
    "plt.title('Comparison of validation loss during training')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(pretr_valid_accuracies, label='GloVe pre-trained')\n",
    "plt.plot(valid_accuracies, label='Randomly initialized')\n",
    "plt.legend()\n",
    "plt.title('Comparison of validation accuracy during training')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, GloVe embeddings significantly outperform the randomly initialized ones. Can you guess why is that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part V: Exercises\n",
    "\n",
    "### Play with the training parameters\n",
    "There is more than pre-trained weights that can change the outcome of a training. Try to change some of the following parameters and report how this changes the outcome of your results.\n",
    "* batch size of the iterators\n",
    "* learning rate of the optimizer\n",
    "* increasing the number of epochs\n",
    " \n",
    " _Note: do not forget to re-initialize your variables (most importantly dataloader, model, optimizer). To be on the safe-side, you can use different namings for these variables in every experiment_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-trained embeddings\n",
    "\n",
    "Try to use different pre-trained embeddings than the ones shown in this lab. You can use different versions of GloVe or entirely new pre-trained vectors. You can check all that are currently available [here](https://pytorch.org/text/stable/_modules/torchtext/vocab.html#Vocab.load_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving the model (simple)\n",
    "\n",
    "Let's try to improve our `SentimentAnalysisModel`.\n",
    "\n",
    "In this exercise we took the mean of our embeddings after making a forward pass through the embedding layer. In practice, there is more efficient way using an `torch.nn.EmbeddingBag` [link](https://pytorch.org/docs/stable/generated/torch.nn.EmbeddingBag.html#torch.nn.EmbeddingBag). This will make training faster and will also remove the need for taking the mean of the embeddings. Create a new class that contains the same layers as `SentimentAnalysisModel` but replacing the embedding layer with an embedding bag. Report if this changes the results in any way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another simple exercise you can perform is adding another linear layer after the embeddings and before the final fully connected one. Try this with different dimensionalities and report the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving the model (advanced)\n",
    "\n",
    "These days, there are much more powerful components that researchers use instead of only embedding and linear layers. Recurrent neural networks (RNN) are one of the most popular ones. You can read about them here and specifically about PyTorch implementation [here](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html). \n",
    "\n",
    "Try to improve your model by including a `torch.nn.RNN` module. Once this is working, you can also try a more sophisticated implementation, such as `torch.nn.LSTM` or `torch.nn.GRU`. You can experiment with the amount of layers and the bi-directionality. Practice shows that bi-directional RNNs usually perform better than uni-directional. Is this also valid for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab-env",
   "language": "python",
   "name": "lab-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
